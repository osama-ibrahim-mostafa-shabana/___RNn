{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p95xCLks7tPp",
        "outputId": "b60d8191-0359-48b7-9f5a-11425e2cace6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100  Loss: 1.3748  Accuracy: 100.00%\n",
            "Epoch 11/100  Loss: 0.7460  Accuracy: 100.00%\n",
            "Epoch 21/100  Loss: 0.3773  Accuracy: 100.00%\n",
            "Epoch 31/100  Loss: 0.1972  Accuracy: 100.00%\n",
            "Epoch 41/100  Loss: 0.1170  Accuracy: 100.00%\n",
            "Epoch 51/100  Loss: 0.0780  Accuracy: 100.00%\n",
            "Epoch 61/100  Loss: 0.0566  Accuracy: 100.00%\n",
            "Epoch 71/100  Loss: 0.0436  Accuracy: 100.00%\n",
            "Epoch 81/100  Loss: 0.0351  Accuracy: 100.00%\n",
            "Epoch 91/100  Loss: 0.0291  Accuracy: 100.00%\n",
            "Epoch 100/100  Loss: 0.0251  Accuracy: 100.00%\n",
            "\n",
            "Final prediction after training:\n",
            "Predicted word: friends\n",
            "Target word: friends\n",
            "Final Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "# Helper functions\n",
        "def softmax(x):\n",
        "    exps = [math.exp(i) for i in x]\n",
        "    total = sum(exps)\n",
        "    return [i/total for i in exps]\n",
        "\n",
        "def tanh(x):\n",
        "    return [math.tanh(i) for i in x]\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return [1 - math.tanh(i)**2 for i in x]\n",
        "\n",
        "def vector_add(v1, v2):\n",
        "    return [i + j for i, j in zip(v1, v2)]\n",
        "\n",
        "def matrix_vector_mul(matrix, vector):\n",
        "    return [sum(m*v for m,v in zip(row, vector)) for row in matrix]\n",
        "\n",
        "def cross_entropy(predicted, target_index):\n",
        "    return -math.log(predicted[target_index] + 1e-10)\n",
        "\n",
        "def one_hot(index, size):\n",
        "    vec = [0]*size\n",
        "    vec[index] = 1\n",
        "    return vec\n",
        "\n",
        "def random_matrix(rows, cols):\n",
        "    return [[random.uniform(-0.1, 0.1) for _ in range(cols)] for _ in range(rows)]\n",
        "\n",
        "def zero_vector(size):\n",
        "    return [0.0 for _ in range(size)]\n",
        "\n",
        "# Sentence: \"we are best friends\"\n",
        "word_to_idx = {\"we\":0, \"are\":1, \"best\":2, \"friends\":3}\n",
        "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
        "\n",
        "inputs = [\"we\", \"are\", \"best\"]\n",
        "target = \"friends\"\n",
        "\n",
        "input_vectors = [one_hot(word_to_idx[word], 4) for word in inputs]\n",
        "target_index = word_to_idx[target]\n",
        "\n",
        "# Initialize Parameters\n",
        "input_size = 4\n",
        "hidden_size = 4\n",
        "output_size = 4\n",
        "\n",
        "W_xh = random_matrix(hidden_size, input_size)\n",
        "W_hh = random_matrix(hidden_size, hidden_size)\n",
        "b_h = zero_vector(hidden_size)\n",
        "\n",
        "W_hy = random_matrix(output_size, hidden_size)\n",
        "b_y = zero_vector(output_size)\n",
        "\n",
        "# Training settings\n",
        "learning_rate = 0.1\n",
        "epochs = 100\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    h = zero_vector(hidden_size)\n",
        "    h_list = []\n",
        "    y = None\n",
        "\n",
        "    for x in input_vectors:\n",
        "        pre_activation = vector_add(\n",
        "            matrix_vector_mul(W_xh, x),\n",
        "            matrix_vector_mul(W_hh, h)\n",
        "        )\n",
        "        pre_activation = vector_add(pre_activation, b_h)\n",
        "        h = tanh(pre_activation)\n",
        "        h_list.append(h)\n",
        "\n",
        "    logits = vector_add(matrix_vector_mul(W_hy, h), b_y)\n",
        "    y = softmax(logits)\n",
        "\n",
        "    # Loss\n",
        "    loss = cross_entropy(y, target_index)\n",
        "\n",
        "    # Prediction and Accuracy\n",
        "    predicted_index = y.index(max(y))\n",
        "    is_correct = (predicted_index == target_index)\n",
        "    accuracy = 100.0 if is_correct else 0.0\n",
        "\n",
        "    # Backward pass\n",
        "    dW_xh = [[0.0]*input_size for _ in range(hidden_size)]\n",
        "    dW_hh = [[0.0]*hidden_size for _ in range(hidden_size)]\n",
        "    db_h = [0.0 for _ in range(hidden_size)]\n",
        "\n",
        "    dW_hy = [[0.0]*hidden_size for _ in range(output_size)]\n",
        "    db_y = [0.0 for _ in range(output_size)]\n",
        "\n",
        "    dy = y[:]\n",
        "    dy[target_index] -= 1\n",
        "\n",
        "    for i in range(output_size):\n",
        "        for j in range(hidden_size):\n",
        "            dW_hy[i][j] += dy[i] * h[j]\n",
        "    for i in range(output_size):\n",
        "        db_y[i] += dy[i]\n",
        "\n",
        "    dh = [0.0 for _ in range(hidden_size)]\n",
        "    for j in range(hidden_size):\n",
        "        for i in range(output_size):\n",
        "            dh[j] += W_hy[i][j] * dy[i]\n",
        "\n",
        "    for t in reversed(range(len(input_vectors))):\n",
        "        dh_raw = [a*b for a,b in zip(dh, tanh_derivative(h_list[t]))]\n",
        "\n",
        "        for i in range(hidden_size):\n",
        "            for j in range(input_size):\n",
        "                dW_xh[i][j] += dh_raw[i] * input_vectors[t][j]\n",
        "            for j in range(hidden_size):\n",
        "                prev_h = h_list[t-1] if t != 0 else zero_vector(hidden_size)\n",
        "                dW_hh[i][j] += dh_raw[i] * prev_h[j]\n",
        "            db_h[i] += dh_raw[i]\n",
        "\n",
        "        dh_new = [0.0 for _ in range(hidden_size)]\n",
        "        for j in range(hidden_size):\n",
        "            for i in range(hidden_size):\n",
        "                dh_new[j] += W_hh[i][j] * dh_raw[i]\n",
        "        dh = dh_new\n",
        "\n",
        "    # Update weights\n",
        "    for i in range(hidden_size):\n",
        "        for j in range(input_size):\n",
        "            W_xh[i][j] -= learning_rate * dW_xh[i][j]\n",
        "        for j in range(hidden_size):\n",
        "            W_hh[i][j] -= learning_rate * dW_hh[i][j]\n",
        "        b_h[i] -= learning_rate * db_h[i]\n",
        "\n",
        "    for i in range(output_size):\n",
        "        for j in range(hidden_size):\n",
        "            W_hy[i][j] -= learning_rate * dW_hy[i][j]\n",
        "        b_y[i] -= learning_rate * db_y[i]\n",
        "\n",
        "    # Print every 10 epochs\n",
        "    if epoch % 10 == 0 or epoch == epochs-1:\n",
        "        print(f\"Epoch {epoch+1}/{epochs}  Loss: {loss:.4f}  Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Final result\n",
        "print(\"\\nFinal prediction after training:\")\n",
        "print(f\"Predicted word: {idx_to_word[predicted_index]}\")\n",
        "print(f\"Target word: {target}\")\n",
        "print(f\"Final Accuracy: {accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8YBZusWv8Nii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}